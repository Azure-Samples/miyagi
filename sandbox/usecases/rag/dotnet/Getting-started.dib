#!meta

{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"languageName":"csharp","name":"csharp"}]}}

#!markdown

# Getting Started with Miyagi's Retrieval Augmented Generation (RaG) Workflow using Azure Cognitive Search (ACS) and Semantic Kernel

To quickly get started, follow these steps:

1. Ensure the [Polyglot notebooks extension](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) is installed.
2. [Create a new Azure OpenAI service (or use an existing OpenAI service)](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio#prerequisites).
3. [Deploy the `gpt-35-turbo` and `text-embeddings-ada-002` models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#working-with-models).
4. [Create an Azure Cognitive Search instance and enable the Semantic Search capability](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview#enable-semantic-search).
5. Copy the `.env.example` file from the `rag` folder to `dotnet/.env` and paste the corresponding values from the resources you provisioned in the earlier steps.
6. Click on `Run All`.

> This guide is based on [Devis' ACS notebooks](https://github.com/dluc/Azure-Cognitive-Search-20230720)

#!markdown

## Load settings from .env file

#!csharp

#r "nuget: dotenv.net, 3.1.2"
dotenv.net.DotEnv.Load();
var env = dotenv.net.DotEnv.Read();

#!markdown

## Prepare kernel using Azure Cognitive Search

#!csharp

#r "nuget: Microsoft.SemanticKernel, 0.17.230718.1-preview"
#r "nuget: Microsoft.SemanticKernel.Connectors.Memory.AzureSearch, 0.17.230718.1-preview"

using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Connectors.Memory.AzureSearch;
using Microsoft.SemanticKernel.Memory;
using Microsoft.SemanticKernel.Text;
using System.IO;

var kernel = Kernel.Builder
    
    // Use Azure Cognitive Search for the kernel Memory
    .WithMemoryStorage(new AzureSearchMemoryStore(
        env["AZURE_SEARCH_ENDPOINT"],
        env["AZURE_SEARCH_API_KEY"]))

    // Use Azure OpenAI for Embeddings (model: text-embedding-ada-002)
    .WithAzureTextEmbeddingGenerationService(
        deploymentName: "text-embedding-ada-002",
        endpoint: env["AZURE_OPENAI_ENDPOINT"],
        apiKey: env["AZURE_OPENAI_API_KEY"])

    // Use Azure OpenAI for Semantic Functions (model = gpt-35-turbo)
    .WithAzureChatCompletionService(
        deploymentName: "gpt-35-turbo",
        endpoint: env["AZURE_OPENAI_ENDPOINT"],
        apiKey: env["AZURE_OPENAI_API_KEY"])
        
    .Build();

#!markdown

## Vectorize and persist embeddings in Azure Cognitive Search with Semantic Kernel

#!csharp

var dataset = "intelligent-investor.txt";
var recommendationServicePath = "../../../../services/recommendation-service/dotnet";
const int MaxTokensPerParagraph = 160;
const int MaxTokensPerLine = 60;

// Read file from local file system
var filePath = Path.Combine(recommendationServicePath, "resources", "sample-datasets", dataset);
var streamReader = new StreamReader(filePath);
var text = await streamReader.ReadToEndAsync();

// Chunk, generate embeddings, and persist to vectordb
var memoryCollectionName = "userId";

var lines = TextChunker.SplitPlainTextLines(text, MaxTokensPerLine);
var chunks = TextChunker.SplitPlainTextParagraphs(lines, MaxTokensPerParagraph);

for (var i = 0; i < chunks.Count; i++)
{
    var chunk = chunks[i];
    var key = await kernel.Memory.SaveInformationAsync(
        memoryCollectionName,
        chunk,
        $"{dataset}-{i}",
        $"Dataset: {dataset} Chunk: {i}",
        i.ToString());
}
System.Console.WriteLine($"Saved {chunks.Count} chunks to memory collection {memoryCollectionName}");

#!markdown

## Search and retrieve documents using Semantic Kernel

#!csharp

var query = "Ben Graham's investment philosophy";
Console.WriteLine(query + "\n");

var results = kernel.Memory.SearchAsync(collection: memoryCollectionName, query, limit: 2);
await foreach(var result in results)
{
    Console.WriteLine("   " + result.Metadata.Text);
    Console.WriteLine("   Relevance: " + result.Relevance + "\n");
}

#!markdown

## Grounding Miyagi prompts with SK's Memory "recall"

> Note that this prompt template (semantic function) is located under services/reccommendation-service/dotnet/plugins/AdvisorPlugin

#!csharp

using Microsoft.SemanticKernel.Skills.Core;
using Microsoft.SemanticKernel.SkillDefinition;

// recall is from the TextMemorySkill, which does the retrieval step
kernel.ImportSkill(new TextMemorySkill());

var pluginFolder = $"{recommendationServicePath}/plugins";
var advisorPlugin = kernel.ImportSemanticSkillFromDirectory(pluginFolder, "AdvisorPlugin");
advisorPlugin

#!csharp

var context = kernel.CreateNewContext();
context[TextMemorySkill.CollectionParam] = memoryCollectionName;

var result = await skFunction.InvokeAsync("Are growth stocks better, according to Ben Graham?", context);
Console.WriteLine(result);

#!markdown

![RaG Workflow](../../../../assets/images/sk-memory-orchestration.png)
